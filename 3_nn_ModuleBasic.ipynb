{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcGGO0x1y94W1FdxMUDM7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruvit-Agrawal/PyTorch/blob/main/3_nn_ModuleBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_4mAs39GvzL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(nn.Module):  #inhereting nn class\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()    #calling instructor of parent class using super() function\n",
        "        self.linear1=nn.Linear(in_features=num_features,out_features=4)        #initalising  linear layer 1\n",
        "        self.relu=nn.Sigmoid()                                                 #inialiting activation function\n",
        "\n",
        "        self.linear2=nn.Linear(in_features=4, out_features=1)             #initalising linear layer 2\n",
        "        self.sigmoid=nn.Sigmoid()                                         #initalising activation function\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.linear1(x)\n",
        "        x=self.relu(x)\n",
        "        x=self.linear2(x)\n",
        "        x=self.sigmoid(x)\n",
        "        return (x)"
      ],
      "metadata": {
        "id": "Bj3Ohhe7HA8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy dataset\n",
        "X=torch.rand(100,10)\n",
        "y=torch.rand(100,1)\n",
        "\n",
        "#model instance\n",
        "model=MyModel(X.shape[1])\n",
        "\n",
        "#forward pass\n",
        "model(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gM0bLhMIrNR",
        "outputId": "4e004faf-1522-4eba-ef9c-611338d088a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5059],\n",
              "        [0.5049],\n",
              "        [0.5042],\n",
              "        [0.5110],\n",
              "        [0.5063],\n",
              "        [0.5041],\n",
              "        [0.4989],\n",
              "        [0.4992],\n",
              "        [0.4976],\n",
              "        [0.5100],\n",
              "        [0.5073],\n",
              "        [0.5015],\n",
              "        [0.5104],\n",
              "        [0.4974],\n",
              "        [0.5007],\n",
              "        [0.5015],\n",
              "        [0.4990],\n",
              "        [0.5157],\n",
              "        [0.4926],\n",
              "        [0.5109],\n",
              "        [0.4952],\n",
              "        [0.5012],\n",
              "        [0.5041],\n",
              "        [0.5081],\n",
              "        [0.5054],\n",
              "        [0.5097],\n",
              "        [0.5085],\n",
              "        [0.4999],\n",
              "        [0.5088],\n",
              "        [0.5124],\n",
              "        [0.5063],\n",
              "        [0.4960],\n",
              "        [0.4996],\n",
              "        [0.5100],\n",
              "        [0.5025],\n",
              "        [0.4999],\n",
              "        [0.5053],\n",
              "        [0.5036],\n",
              "        [0.5095],\n",
              "        [0.5069],\n",
              "        [0.4988],\n",
              "        [0.5059],\n",
              "        [0.5066],\n",
              "        [0.5033],\n",
              "        [0.4986],\n",
              "        [0.5114],\n",
              "        [0.5052],\n",
              "        [0.5064],\n",
              "        [0.5050],\n",
              "        [0.5175],\n",
              "        [0.5114],\n",
              "        [0.5036],\n",
              "        [0.5046],\n",
              "        [0.5112],\n",
              "        [0.5105],\n",
              "        [0.5006],\n",
              "        [0.4955],\n",
              "        [0.4987],\n",
              "        [0.5082],\n",
              "        [0.5062],\n",
              "        [0.4978],\n",
              "        [0.5045],\n",
              "        [0.5055],\n",
              "        [0.4978],\n",
              "        [0.5027],\n",
              "        [0.5064],\n",
              "        [0.5006],\n",
              "        [0.5057],\n",
              "        [0.4980],\n",
              "        [0.4999],\n",
              "        [0.5029],\n",
              "        [0.4977],\n",
              "        [0.4976],\n",
              "        [0.5071],\n",
              "        [0.5064],\n",
              "        [0.5071],\n",
              "        [0.5045],\n",
              "        [0.5018],\n",
              "        [0.5093],\n",
              "        [0.5057],\n",
              "        [0.5043],\n",
              "        [0.4990],\n",
              "        [0.5068],\n",
              "        [0.4967],\n",
              "        [0.5024],\n",
              "        [0.5002],\n",
              "        [0.5138],\n",
              "        [0.5011],\n",
              "        [0.4962],\n",
              "        [0.5102],\n",
              "        [0.4975],\n",
              "        [0.5040],\n",
              "        [0.5035],\n",
              "        [0.5076],\n",
              "        [0.4958],\n",
              "        [0.5092],\n",
              "        [0.5132],\n",
              "        [0.5009],\n",
              "        [0.4980],\n",
              "        [0.5126]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model weights\n",
        "model.linear2.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiasWN6wJNj4",
        "outputId": "d0577b17-a58e-4a9f-b944-f5e522deb5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0.3846, 0.2517, 0.2093, 0.1287]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "a9GKEl7dKZcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary"
      ],
      "metadata": {
        "id": "heWVZkEAKbnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create summary\n",
        "summary(model=model,input_size=(100,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGkxLqNBKejp",
        "outputId": "5c3165e3-6dad-4bfa-e261-8b6ce0be33ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyModel                                  [100, 1]                  --\n",
              "├─Linear: 1-1                            [100, 4]                  44\n",
              "├─Sigmoid: 1-2                           [100, 4]                  --\n",
              "├─Linear: 1-3                            [100, 1]                  5\n",
              "├─Sigmoid: 1-4                           [100, 1]                  --\n",
              "==========================================================================================\n",
              "Total params: 49\n",
              "Trainable params: 49\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.01\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_using_sequential(nn.Module):  #inhereting nn class\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()    #calling instructor of parent class using super() function\n",
        "\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(in_features=num_features,out_features=4),        #initalising  linear layer 1\n",
        "            nn.ReLU(),                                                 #inialiting activation function\n",
        "\n",
        "            nn.Linear(in_features=4, out_features=1),             #initalising linear layer 2\n",
        "            nn.Sigmoid()                                         #initalising activation function\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        out=self.network(x)\n",
        "        return (x)"
      ],
      "metadata": {
        "id": "cNA27AsXQTmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy dataset\n",
        "X=torch.rand(100,10)\n",
        "y=torch.rand(100,1)\n",
        "\n",
        "#model instance\n",
        "model=MyModel_using_sequential(X.shape[1])\n",
        "\n",
        "#forward pass\n",
        "model(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92dqnr02Q-77",
        "outputId": "0d349d92-9794-4663-919c-81f1bb358c71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.9513e-01, 9.8117e-01, 3.1090e-01, 9.3044e-02, 4.6141e-01, 5.3395e-01,\n",
              "         5.5490e-01, 7.2994e-01, 9.8205e-01, 8.0320e-01],\n",
              "        [5.2389e-01, 4.7721e-01, 8.2757e-02, 6.6455e-01, 2.7221e-01, 1.1161e-01,\n",
              "         3.6608e-01, 9.0869e-01, 7.4112e-01, 6.6132e-01],\n",
              "        [9.0210e-01, 9.7398e-02, 7.8781e-01, 3.0611e-01, 7.3214e-01, 5.9623e-01,\n",
              "         7.2097e-01, 5.0869e-01, 4.2393e-01, 6.0486e-01],\n",
              "        [4.7026e-01, 1.0705e-02, 2.1239e-01, 9.7708e-01, 1.1335e-01, 7.5438e-01,\n",
              "         3.8109e-01, 8.0884e-01, 7.6240e-01, 9.5505e-01],\n",
              "        [4.5458e-01, 5.3628e-01, 1.1678e-01, 8.1626e-02, 5.4327e-01, 4.4730e-01,\n",
              "         9.3326e-01, 6.5463e-03, 1.3670e-02, 4.7974e-01],\n",
              "        [5.7455e-01, 8.0202e-01, 3.7749e-01, 4.9639e-02, 7.8087e-01, 2.9694e-01,\n",
              "         5.8433e-01, 4.2435e-01, 8.4007e-01, 6.1799e-01],\n",
              "        [5.7285e-01, 5.4558e-01, 8.4602e-02, 1.4157e-02, 5.2042e-01, 6.3907e-01,\n",
              "         1.5156e-01, 2.9609e-01, 8.5163e-01, 3.4710e-01],\n",
              "        [7.0559e-01, 1.1961e-01, 1.0274e-01, 6.8011e-01, 1.3543e-01, 8.5839e-01,\n",
              "         9.0300e-01, 8.1842e-01, 7.5335e-01, 1.7475e-01],\n",
              "        [6.5775e-01, 2.7579e-01, 3.5953e-01, 5.4759e-01, 2.3366e-02, 1.5911e-01,\n",
              "         6.4336e-01, 9.4915e-01, 4.6875e-01, 8.7941e-01],\n",
              "        [6.4986e-02, 3.5759e-02, 3.5764e-01, 6.6257e-01, 6.2473e-01, 1.8436e-01,\n",
              "         1.1966e-01, 3.8704e-01, 4.2871e-01, 9.3708e-01],\n",
              "        [7.2192e-01, 2.0857e-01, 6.2051e-02, 9.5738e-01, 8.4943e-01, 1.4416e-01,\n",
              "         4.6247e-01, 8.6444e-01, 1.3541e-01, 1.5099e-01],\n",
              "        [3.4139e-01, 2.3158e-01, 3.8586e-01, 8.5527e-01, 2.9382e-01, 6.2410e-01,\n",
              "         2.5022e-01, 2.6265e-01, 7.2881e-01, 3.0246e-01],\n",
              "        [8.2384e-01, 1.2424e-01, 8.8873e-02, 2.3136e-01, 2.0041e-01, 6.6628e-01,\n",
              "         5.4863e-01, 7.3468e-01, 6.2905e-01, 6.2887e-01],\n",
              "        [8.5761e-02, 9.2776e-01, 7.5943e-02, 8.4159e-01, 7.0633e-01, 3.2784e-01,\n",
              "         6.5241e-01, 7.0276e-01, 9.0252e-01, 2.6369e-01],\n",
              "        [8.6807e-01, 7.4507e-01, 4.5672e-01, 1.0915e-01, 5.1525e-01, 1.7787e-01,\n",
              "         6.7180e-01, 6.9746e-01, 8.9407e-01, 4.6157e-01],\n",
              "        [6.7047e-01, 8.9975e-01, 4.2522e-01, 5.0591e-01, 4.9947e-01, 2.4923e-01,\n",
              "         6.1694e-01, 5.6680e-01, 5.5259e-01, 9.0352e-01],\n",
              "        [4.7111e-01, 8.0581e-01, 3.0985e-01, 5.5490e-01, 5.4524e-01, 8.2037e-01,\n",
              "         1.2835e-01, 9.0774e-01, 6.8999e-01, 7.7034e-01],\n",
              "        [8.6472e-01, 8.8670e-01, 5.6609e-01, 5.4421e-01, 8.6842e-02, 2.5621e-01,\n",
              "         3.7673e-01, 3.2862e-01, 8.1536e-01, 5.7344e-01],\n",
              "        [9.5201e-01, 7.3662e-01, 1.3204e-01, 9.2491e-01, 4.2813e-01, 8.9955e-01,\n",
              "         8.7241e-01, 9.5860e-01, 1.4671e-01, 6.3249e-01],\n",
              "        [4.9245e-01, 6.5822e-01, 3.6245e-02, 7.2755e-01, 1.1310e-01, 6.3285e-01,\n",
              "         5.1975e-01, 4.7136e-01, 6.2823e-01, 9.5144e-01],\n",
              "        [1.0832e-01, 4.0990e-01, 9.2027e-01, 7.8966e-01, 5.7899e-02, 1.0804e-01,\n",
              "         7.0437e-01, 6.2501e-01, 7.2725e-01, 9.6700e-01],\n",
              "        [9.9529e-01, 8.1797e-01, 5.8186e-01, 2.0024e-01, 8.2331e-01, 9.9313e-01,\n",
              "         1.5275e-01, 9.1851e-01, 8.0670e-01, 4.1299e-01],\n",
              "        [3.8874e-01, 3.0863e-01, 1.2604e-01, 9.8478e-01, 4.1496e-01, 5.1360e-01,\n",
              "         4.8811e-01, 5.2601e-01, 4.0839e-01, 3.7991e-01],\n",
              "        [7.0547e-01, 6.5366e-01, 3.7007e-01, 7.7898e-01, 9.5288e-01, 5.6897e-01,\n",
              "         6.9344e-01, 3.7308e-01, 6.5237e-01, 1.6754e-01],\n",
              "        [5.8891e-01, 4.4933e-01, 9.9921e-01, 6.0722e-01, 4.2271e-02, 5.6924e-01,\n",
              "         3.9289e-01, 3.7828e-01, 5.3502e-01, 3.5266e-01],\n",
              "        [5.8590e-01, 9.0998e-01, 4.8118e-01, 7.0004e-01, 6.2102e-01, 2.6137e-01,\n",
              "         7.6166e-01, 6.9854e-01, 8.2054e-01, 3.6518e-01],\n",
              "        [3.7700e-01, 3.2094e-01, 7.2095e-02, 7.0655e-01, 3.9311e-01, 8.1003e-01,\n",
              "         2.2619e-01, 6.0982e-01, 8.0817e-01, 8.5589e-01],\n",
              "        [1.7328e-01, 1.9136e-01, 6.5826e-01, 6.5538e-01, 7.4074e-01, 3.2544e-01,\n",
              "         5.4797e-01, 4.2312e-01, 2.8369e-01, 3.5766e-01],\n",
              "        [5.5585e-01, 7.0480e-01, 1.7371e-01, 4.2540e-01, 4.4320e-01, 4.6383e-01,\n",
              "         2.8273e-01, 2.7858e-01, 3.1864e-01, 1.0634e-01],\n",
              "        [5.9564e-01, 4.0812e-01, 9.1653e-01, 4.1478e-01, 4.3344e-01, 9.1043e-03,\n",
              "         9.1130e-01, 8.1514e-01, 1.7094e-02, 5.3150e-01],\n",
              "        [5.2525e-01, 4.8037e-01, 4.7787e-01, 5.5421e-01, 8.1027e-01, 7.6600e-03,\n",
              "         5.2752e-01, 7.5201e-01, 5.7858e-01, 1.8746e-01],\n",
              "        [8.3415e-01, 8.6864e-01, 6.3418e-01, 6.2432e-01, 2.1198e-01, 2.9826e-01,\n",
              "         5.9043e-02, 9.0212e-01, 1.4846e-01, 1.8486e-01],\n",
              "        [8.6462e-01, 8.3843e-01, 1.9204e-02, 6.0594e-01, 8.9451e-01, 7.3135e-01,\n",
              "         8.1628e-01, 3.4129e-01, 8.5809e-01, 9.9883e-01],\n",
              "        [6.6156e-01, 9.1120e-01, 8.3755e-01, 7.9491e-01, 8.4774e-01, 8.7096e-01,\n",
              "         2.3983e-01, 1.7239e-01, 6.8991e-01, 1.4732e-01],\n",
              "        [1.9319e-01, 5.5250e-01, 6.6724e-01, 2.5058e-01, 2.9276e-01, 2.8146e-01,\n",
              "         4.0844e-02, 1.9432e-01, 5.8768e-01, 6.7406e-01],\n",
              "        [9.9855e-01, 9.3402e-01, 1.2314e-01, 4.2453e-01, 7.6403e-01, 8.4368e-01,\n",
              "         8.2799e-01, 1.8370e-03, 4.3292e-01, 8.6802e-01],\n",
              "        [8.4570e-01, 4.7636e-01, 8.6121e-01, 7.1802e-01, 7.1792e-01, 5.3582e-01,\n",
              "         5.6028e-01, 8.3596e-01, 4.6169e-01, 2.6348e-01],\n",
              "        [9.9447e-01, 8.1003e-01, 4.8367e-01, 1.4707e-01, 5.1128e-01, 9.7796e-02,\n",
              "         3.4391e-01, 6.9732e-01, 8.7968e-02, 2.9499e-01],\n",
              "        [3.6894e-01, 9.1576e-01, 4.2419e-01, 3.3904e-01, 3.6898e-01, 6.8671e-01,\n",
              "         9.6887e-01, 1.3462e-01, 9.4623e-01, 9.9127e-01],\n",
              "        [3.3369e-01, 6.0133e-01, 7.4771e-01, 5.5325e-01, 2.5077e-02, 1.5430e-01,\n",
              "         2.6177e-01, 3.6972e-01, 9.1082e-01, 5.0828e-01],\n",
              "        [4.3477e-01, 8.4207e-01, 3.3073e-02, 8.1002e-01, 4.2657e-01, 1.5571e-01,\n",
              "         9.1501e-01, 8.3301e-01, 4.9494e-01, 9.0574e-01],\n",
              "        [3.3401e-02, 5.2904e-01, 3.3632e-01, 9.4071e-01, 8.7201e-02, 4.7214e-01,\n",
              "         6.5492e-01, 1.6849e-01, 8.8094e-01, 2.2032e-01],\n",
              "        [6.9523e-01, 4.0091e-03, 8.2595e-02, 4.3308e-01, 7.7285e-02, 6.2867e-01,\n",
              "         4.9773e-01, 7.0264e-02, 3.2014e-01, 4.6828e-01],\n",
              "        [7.4051e-01, 4.7298e-01, 6.1554e-01, 8.4211e-02, 4.2710e-01, 6.9581e-01,\n",
              "         2.4035e-01, 4.1722e-01, 8.4733e-01, 5.8332e-01],\n",
              "        [3.3795e-01, 1.0709e-02, 4.3309e-01, 5.6313e-01, 3.5548e-01, 2.6186e-01,\n",
              "         5.1723e-01, 3.1656e-01, 1.7292e-01, 9.9536e-02],\n",
              "        [2.0035e-02, 1.5953e-01, 4.1280e-01, 5.5360e-01, 6.8801e-01, 9.2876e-01,\n",
              "         6.3647e-01, 4.4019e-01, 4.3849e-02, 9.2057e-01],\n",
              "        [6.2269e-01, 9.4519e-01, 2.9883e-01, 6.7130e-01, 2.1148e-01, 6.1771e-01,\n",
              "         3.2993e-01, 5.8660e-01, 3.7977e-01, 8.1743e-01],\n",
              "        [9.7646e-01, 9.2745e-01, 8.9649e-02, 2.7457e-01, 2.9400e-01, 6.5845e-01,\n",
              "         3.6947e-01, 7.7588e-01, 2.0499e-01, 2.7364e-01],\n",
              "        [9.2789e-01, 3.2965e-01, 7.4706e-01, 9.9388e-01, 7.8454e-01, 2.8431e-05,\n",
              "         6.3940e-01, 9.0395e-01, 8.1186e-01, 5.1923e-01],\n",
              "        [2.0305e-01, 2.8343e-01, 9.6779e-01, 9.4209e-01, 4.3773e-01, 5.5136e-01,\n",
              "         8.0231e-01, 2.9321e-01, 2.7847e-01, 8.4172e-01],\n",
              "        [1.4622e-01, 6.6063e-01, 5.5271e-01, 2.7917e-01, 4.8349e-01, 2.5320e-01,\n",
              "         9.3993e-01, 2.4450e-01, 8.5002e-01, 2.5548e-01],\n",
              "        [9.5952e-01, 6.0097e-01, 8.6263e-02, 9.8360e-01, 3.5129e-01, 1.2959e-01,\n",
              "         4.5092e-03, 3.7636e-01, 6.3220e-01, 6.8780e-01],\n",
              "        [2.2436e-01, 3.0391e-01, 4.9846e-01, 2.8918e-01, 6.7206e-01, 8.9963e-01,\n",
              "         5.3198e-01, 9.7253e-01, 4.7554e-01, 2.4829e-01],\n",
              "        [1.4910e-01, 4.3151e-01, 9.2348e-01, 1.0849e-01, 1.0204e-01, 6.5450e-01,\n",
              "         4.7696e-01, 5.7872e-01, 3.3262e-01, 1.1357e-01],\n",
              "        [9.4649e-01, 5.3508e-01, 1.5744e-01, 1.9327e-01, 2.4932e-01, 3.8782e-01,\n",
              "         1.5193e-01, 7.3413e-01, 7.6231e-01, 7.1422e-01],\n",
              "        [7.4775e-01, 1.6531e-01, 8.6465e-01, 9.5670e-01, 7.0593e-01, 9.2277e-02,\n",
              "         5.1537e-01, 1.0755e-01, 4.1847e-02, 1.8331e-01],\n",
              "        [6.3783e-01, 9.1977e-01, 3.9775e-01, 7.0317e-01, 3.4582e-01, 6.2640e-01,\n",
              "         1.1409e-01, 8.6755e-01, 9.1438e-01, 2.0219e-01],\n",
              "        [4.6213e-01, 7.2533e-01, 4.4947e-01, 1.8650e-01, 6.1462e-01, 1.2120e-01,\n",
              "         6.5547e-01, 2.1105e-01, 2.1014e-01, 6.9859e-01],\n",
              "        [5.6162e-01, 3.2886e-01, 3.0287e-01, 8.4297e-02, 4.4390e-01, 1.2243e-01,\n",
              "         9.2815e-01, 6.8455e-01, 8.4638e-01, 2.2480e-01],\n",
              "        [6.4394e-01, 1.3504e-01, 7.8382e-01, 3.5219e-01, 4.1779e-02, 9.8439e-01,\n",
              "         1.6503e-01, 9.3885e-01, 9.2324e-01, 7.9068e-01],\n",
              "        [1.8417e-01, 9.5689e-01, 5.3266e-01, 1.9646e-01, 3.4178e-01, 9.8676e-01,\n",
              "         5.6281e-01, 6.7124e-01, 7.8113e-01, 5.5608e-01],\n",
              "        [1.3387e-01, 3.5586e-01, 1.4851e-01, 1.8820e-01, 3.5239e-01, 2.3981e-02,\n",
              "         7.8822e-01, 9.0576e-01, 3.2697e-01, 8.8274e-01],\n",
              "        [5.2972e-01, 6.9144e-01, 2.0976e-01, 9.1468e-01, 2.6009e-01, 2.0123e-01,\n",
              "         4.3701e-01, 1.0132e-01, 9.8965e-01, 6.1346e-01],\n",
              "        [7.9885e-01, 6.2685e-01, 3.8805e-01, 4.0687e-01, 4.6796e-01, 7.7151e-01,\n",
              "         4.9474e-01, 7.3209e-01, 1.4628e-01, 3.7759e-01],\n",
              "        [8.7511e-01, 3.1725e-01, 2.8941e-01, 3.0849e-01, 8.7600e-01, 8.0341e-01,\n",
              "         3.0363e-02, 4.3094e-01, 1.5503e-01, 3.1917e-01],\n",
              "        [4.8817e-01, 5.1685e-01, 3.1979e-01, 9.5365e-01, 2.5554e-01, 2.1859e-01,\n",
              "         2.7864e-01, 5.6470e-01, 2.0412e-01, 5.8793e-01],\n",
              "        [9.9562e-01, 1.3496e-01, 8.1898e-02, 1.8832e-03, 7.4362e-01, 6.2790e-01,\n",
              "         2.3980e-01, 9.9716e-01, 2.7548e-01, 8.8494e-01],\n",
              "        [8.5942e-02, 2.3196e-01, 5.8089e-01, 4.3868e-01, 8.1394e-01, 7.5464e-02,\n",
              "         5.2050e-01, 8.8637e-01, 7.4544e-01, 6.9231e-01],\n",
              "        [3.1230e-01, 5.1734e-01, 8.7897e-01, 7.2635e-01, 3.8413e-02, 8.4508e-01,\n",
              "         9.7357e-01, 3.6205e-01, 5.8676e-01, 4.2148e-01],\n",
              "        [1.2666e-02, 1.2472e-01, 4.4089e-01, 1.6888e-01, 5.0954e-01, 7.7815e-01,\n",
              "         7.6758e-01, 2.2998e-01, 9.4018e-01, 3.5765e-01],\n",
              "        [5.7254e-01, 6.0880e-01, 1.8906e-02, 4.7897e-01, 4.2934e-03, 4.9511e-01,\n",
              "         7.8277e-01, 3.3418e-01, 6.1669e-01, 7.6019e-01],\n",
              "        [5.9510e-01, 5.3177e-01, 1.4917e-01, 8.9215e-01, 4.7206e-01, 3.4966e-01,\n",
              "         9.8925e-01, 1.7149e-01, 5.9983e-01, 4.0447e-01],\n",
              "        [9.3328e-01, 3.5030e-01, 9.2538e-01, 3.2481e-02, 3.4352e-03, 9.1118e-01,\n",
              "         3.8992e-01, 1.3314e-01, 2.4966e-02, 4.7250e-01],\n",
              "        [3.2965e-01, 4.0064e-01, 1.3840e-01, 4.2231e-01, 1.9067e-01, 9.5453e-01,\n",
              "         7.3775e-01, 9.8638e-01, 5.9211e-01, 3.7044e-01],\n",
              "        [8.7400e-01, 9.7889e-01, 1.4015e-01, 9.5522e-01, 5.7701e-01, 3.0354e-01,\n",
              "         5.5930e-01, 5.1160e-01, 1.2611e-01, 2.3559e-01],\n",
              "        [9.8344e-01, 1.1302e-01, 8.3887e-01, 3.6410e-01, 8.0704e-01, 2.3182e-01,\n",
              "         3.8857e-01, 6.6606e-01, 3.2078e-01, 7.4480e-01],\n",
              "        [7.9560e-01, 9.4477e-01, 5.4572e-01, 5.1602e-01, 3.2243e-01, 7.0885e-01,\n",
              "         5.5371e-01, 1.1841e-01, 4.3164e-01, 5.5935e-01],\n",
              "        [8.3126e-01, 4.3848e-01, 3.4017e-01, 7.2779e-01, 4.4176e-01, 5.0885e-01,\n",
              "         6.8962e-01, 2.7189e-01, 4.6411e-01, 2.7126e-01],\n",
              "        [7.9006e-02, 6.4178e-02, 5.8095e-01, 1.6748e-01, 7.3104e-01, 6.5531e-01,\n",
              "         6.8858e-01, 3.2195e-01, 7.5555e-01, 4.1287e-01],\n",
              "        [1.4090e-01, 7.7520e-01, 2.1955e-01, 6.6399e-01, 5.2906e-02, 7.5183e-01,\n",
              "         4.3817e-01, 6.3259e-01, 5.6495e-01, 2.5096e-02],\n",
              "        [1.0021e-01, 9.9487e-03, 2.5733e-01, 5.3755e-01, 1.9126e-01, 3.2680e-01,\n",
              "         8.3284e-01, 2.4741e-01, 1.4404e-01, 2.8420e-01],\n",
              "        [7.4019e-01, 2.7874e-01, 4.2439e-01, 2.1657e-01, 2.2629e-01, 1.6081e-01,\n",
              "         9.1743e-01, 6.7881e-02, 8.9792e-01, 6.3785e-01],\n",
              "        [1.8582e-01, 7.1617e-01, 2.2809e-01, 8.6648e-01, 3.1524e-01, 7.9047e-01,\n",
              "         3.2456e-01, 3.5788e-01, 2.2978e-01, 3.9658e-01],\n",
              "        [5.2870e-01, 8.8814e-01, 2.6408e-01, 8.1308e-01, 9.3439e-01, 3.7192e-01,\n",
              "         5.5745e-01, 5.3376e-01, 5.7651e-01, 1.5496e-01],\n",
              "        [8.7179e-01, 7.1848e-02, 5.2685e-01, 9.3267e-01, 3.9658e-01, 7.8957e-03,\n",
              "         4.2930e-03, 1.7338e-01, 3.6030e-01, 4.8753e-01],\n",
              "        [4.5096e-01, 4.6227e-01, 9.4220e-01, 9.1691e-01, 5.5828e-01, 4.5239e-01,\n",
              "         9.6786e-01, 1.7406e-01, 6.8439e-01, 5.0782e-01],\n",
              "        [5.5349e-01, 1.4074e-01, 5.7938e-01, 3.4207e-01, 5.2852e-01, 7.6791e-01,\n",
              "         9.8584e-02, 6.4929e-01, 3.5731e-01, 3.8543e-01],\n",
              "        [4.8914e-01, 1.6347e-01, 6.8854e-01, 8.9802e-02, 4.4123e-01, 8.7723e-01,\n",
              "         1.1706e-01, 2.3150e-01, 6.2985e-01, 8.1927e-01],\n",
              "        [1.2063e-01, 3.3221e-01, 7.8961e-01, 4.1458e-01, 2.8722e-01, 8.8001e-01,\n",
              "         1.2178e-01, 1.0846e-02, 6.0076e-01, 8.9821e-01],\n",
              "        [9.2529e-01, 4.0957e-01, 5.8251e-01, 4.8050e-01, 3.6014e-02, 4.0354e-01,\n",
              "         1.6047e-02, 9.1990e-01, 6.3205e-01, 9.0994e-02],\n",
              "        [8.6079e-01, 5.5114e-01, 7.9633e-01, 1.6102e-01, 5.8933e-02, 4.8810e-01,\n",
              "         3.4512e-01, 7.5042e-01, 1.9328e-01, 3.7645e-01],\n",
              "        [6.0103e-01, 5.8903e-01, 1.4080e-01, 9.6868e-02, 3.4872e-02, 7.3144e-01,\n",
              "         9.9212e-01, 2.3526e-01, 6.3056e-01, 9.7606e-01],\n",
              "        [6.7210e-01, 5.9421e-01, 8.7374e-01, 3.6414e-01, 2.3094e-01, 1.2668e-02,\n",
              "         5.1401e-01, 7.4953e-01, 9.1988e-01, 7.8889e-02],\n",
              "        [2.9808e-01, 5.7327e-01, 9.6804e-01, 9.5858e-01, 6.3362e-01, 2.3697e-01,\n",
              "         2.3480e-01, 9.1557e-02, 3.0975e-01, 1.1482e-01],\n",
              "        [9.6027e-01, 7.1246e-01, 1.0948e-02, 9.1603e-03, 1.3629e-01, 6.2114e-01,\n",
              "         5.3755e-01, 2.4357e-01, 2.7078e-01, 9.5486e-01],\n",
              "        [2.9978e-02, 3.3364e-01, 4.6980e-02, 1.9197e-01, 2.9441e-01, 3.6537e-01,\n",
              "         4.2911e-01, 3.9839e-02, 5.5423e-01, 5.4163e-02],\n",
              "        [3.0810e-02, 4.5424e-01, 4.4469e-01, 2.5706e-01, 3.2286e-01, 6.8773e-01,\n",
              "         8.6714e-01, 2.7400e-01, 1.1259e-01, 6.3290e-01],\n",
              "        [6.9437e-01, 9.8018e-01, 7.5252e-01, 6.2936e-02, 9.7775e-01, 3.7984e-01,\n",
              "         4.4072e-01, 9.4295e-01, 1.8558e-01, 8.7249e-01],\n",
              "        [3.1979e-01, 5.1014e-01, 7.4391e-01, 7.2492e-01, 2.7654e-01, 1.2064e-01,\n",
              "         1.6265e-01, 2.8247e-01, 9.0309e-01, 3.0311e-01],\n",
              "        [6.4192e-01, 8.6666e-01, 3.2456e-02, 6.3561e-01, 5.0118e-01, 5.3670e-01,\n",
              "         4.5023e-01, 7.9098e-01, 1.9450e-01, 5.5433e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,input_size=(100,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gGVZOFcRQwx",
        "outputId": "46f2401b-6f3c-4c73-f0f6-3e9ef5cbe452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "MyModel_using_sequential                 [100, 10]                 --\n",
              "├─Sequential: 1-1                        [100, 1]                  --\n",
              "│    └─Linear: 2-1                       [100, 4]                  44\n",
              "│    └─ReLU: 2-2                         [100, 4]                  --\n",
              "│    └─Linear: 2-3                       [100, 1]                  5\n",
              "│    └─Sigmoid: 2-4                      [100, 1]                  --\n",
              "==========================================================================================\n",
              "Total params: 49\n",
              "Trainable params: 49\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.01\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel_using_optim(nn.Module):  #inhereting nn class\n",
        "\n",
        "    def __init__(self, num_features):\n",
        "        super().__init__()    #calling instructor of parent class using super() function\n",
        "\n",
        "        self.network=nn.Sequential(\n",
        "            nn.Linear(in_features=num_features,out_features=4),        #initalising  linear layer 1\n",
        "            nn.ReLU(),                                                 #inialiting activation function\n",
        "\n",
        "            nn.Linear(in_features=4, out_features=1),             #initalising linear layer 2\n",
        "            nn.Sigmoid()                                         #initalising activation function\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        y_pred=self.network(x)\n",
        "        return (y_pred)\n",
        "\n",
        "    def loss(self,y_pred,y):\n",
        "        loss_fn=nn.BCELoss()\n",
        "        loss=loss_fn(y_pred,y)\n",
        "        return (loss)\n",
        "\n",
        "    def train(self,loss,epoch=25,lr=0.01):\n",
        "\n",
        "        #setting optimizer\n",
        "        optimizer=torch.optim.SGD(params=self.network.parameters(),lr=lr)        # .parameters()--> stores all the trainable paramaets\n",
        "        for i in range(epoch):\n",
        "\n",
        "            #forward\n",
        "            y_pred=self.network(X)\n",
        "\n",
        "            #loss\n",
        "            loss=self.loss(y_pred=y_pred,y=y)\n",
        "\n",
        "\n",
        "            optimizer.zero_grad()                #clear gradient\n",
        "            loss.backward()                      #backtrack\n",
        "            optimizer.step()                     #update parameters\n",
        "\n",
        "            #print loss\n",
        "            print(f\"epoch:{i+1},loss:{loss.item()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "oL0DG7UUVxa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dummy dataset\n",
        "X=torch.rand(100,10)\n",
        "y=torch.rand(100,1)\n",
        "\n",
        "#model instance\n",
        "model=MyModel_using_optim(X.shape[1])\n",
        "\n"
      ],
      "metadata": {
        "id": "EY3WAzwDXjkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "model.train(loss=loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4GQCzaWYi23",
        "outputId": "b4c81bd5-b7fa-4f01-b0b5-84bec0ec55f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1,loss:0.6933513879776001\n",
            "epoch:2,loss:0.693347692489624\n",
            "epoch:3,loss:0.6933439373970032\n",
            "epoch:4,loss:0.6933403611183167\n",
            "epoch:5,loss:0.6933367252349854\n",
            "epoch:6,loss:0.6933330297470093\n",
            "epoch:7,loss:0.6933294534683228\n",
            "epoch:8,loss:0.6933258175849915\n",
            "epoch:9,loss:0.6933221220970154\n",
            "epoch:10,loss:0.6933184862136841\n",
            "epoch:11,loss:0.6933149099349976\n",
            "epoch:12,loss:0.6933112144470215\n",
            "epoch:13,loss:0.6933075189590454\n",
            "epoch:14,loss:0.6933040022850037\n",
            "epoch:15,loss:0.6933003067970276\n",
            "epoch:16,loss:0.6932967901229858\n",
            "epoch:17,loss:0.6932930946350098\n",
            "epoch:18,loss:0.6932895183563232\n",
            "epoch:19,loss:0.6932858824729919\n",
            "epoch:20,loss:0.6932823061943054\n",
            "epoch:21,loss:0.6932786703109741\n",
            "epoch:22,loss:0.6932750940322876\n",
            "epoch:23,loss:0.6932713985443115\n",
            "epoch:24,loss:0.6932678818702698\n",
            "epoch:25,loss:0.6932643055915833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,input_size=(100,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNMe_CshYtER",
        "outputId": "ed704feb-1158-4653-a210-b89a2f159932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1,loss:0.693260669708252\n",
            "epoch:2,loss:0.6932570934295654\n",
            "epoch:3,loss:0.6932534575462341\n",
            "epoch:4,loss:0.6932498812675476\n",
            "epoch:5,loss:0.6932463049888611\n",
            "epoch:6,loss:0.6932427287101746\n",
            "epoch:7,loss:0.693239152431488\n",
            "epoch:8,loss:0.6932355761528015\n",
            "epoch:9,loss:0.6932319402694702\n",
            "epoch:10,loss:0.6932284832000732\n",
            "epoch:11,loss:0.6932248473167419\n",
            "epoch:12,loss:0.6932212710380554\n",
            "epoch:13,loss:0.6932177543640137\n",
            "epoch:14,loss:0.6932141184806824\n",
            "epoch:15,loss:0.6932106018066406\n",
            "epoch:16,loss:0.6932070851325989\n",
            "epoch:17,loss:0.6932035088539124\n",
            "epoch:18,loss:0.6931999921798706\n",
            "epoch:19,loss:0.6931964159011841\n",
            "epoch:20,loss:0.6931928396224976\n",
            "epoch:21,loss:0.6931893825531006\n",
            "epoch:22,loss:0.6931857466697693\n",
            "epoch:23,loss:0.6931822299957275\n",
            "epoch:24,loss:0.6931787133216858\n",
            "epoch:25,loss:0.6931751370429993\n",
            "epoch:1,loss:0.6931716203689575\n",
            "epoch:2,loss:0.693168044090271\n",
            "epoch:3,loss:0.6931645274162292\n",
            "epoch:4,loss:0.6931610703468323\n",
            "epoch:5,loss:0.6931574940681458\n",
            "epoch:6,loss:0.693153977394104\n",
            "epoch:7,loss:0.6931504607200623\n",
            "epoch:8,loss:0.6931468844413757\n",
            "epoch:9,loss:0.693143367767334\n",
            "epoch:10,loss:0.6931399703025818\n",
            "epoch:11,loss:0.6931363940238953\n",
            "epoch:12,loss:0.6931329369544983\n",
            "epoch:13,loss:0.6931293606758118\n",
            "epoch:14,loss:0.6931259036064148\n",
            "epoch:15,loss:0.693122386932373\n",
            "epoch:16,loss:0.6931188106536865\n",
            "epoch:17,loss:0.6931154131889343\n",
            "epoch:18,loss:0.6931118965148926\n",
            "epoch:19,loss:0.6931084394454956\n",
            "epoch:20,loss:0.6931048631668091\n",
            "epoch:21,loss:0.6931013464927673\n",
            "epoch:22,loss:0.6930978894233704\n",
            "epoch:23,loss:0.6930944919586182\n",
            "epoch:24,loss:0.6930909156799316\n",
            "epoch:25,loss:0.6930873990058899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [100, 1]                  --\n",
              "│    └─Linear: 2-1                       [100, 4]                  44\n",
              "│    └─ReLU: 2-2                         [100, 4]                  --\n",
              "│    └─Linear: 2-3                       [100, 1]                  5\n",
              "│    └─Sigmoid: 2-4                      [100, 1]                  --\n",
              "├─Sequential: 1-2                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-5                       [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-6                         [100, 4]                  --\n",
              "│    └─Linear: 2-7                       [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-8                      [100, 1]                  --\n",
              "├─Sequential: 1-3                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-9                       [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-10                        [100, 4]                  --\n",
              "│    └─Linear: 2-11                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-12                     [100, 1]                  --\n",
              "├─Sequential: 1-4                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-13                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-14                        [100, 4]                  --\n",
              "│    └─Linear: 2-15                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-16                     [100, 1]                  --\n",
              "├─Sequential: 1-5                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-17                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-18                        [100, 4]                  --\n",
              "│    └─Linear: 2-19                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-20                     [100, 1]                  --\n",
              "├─Sequential: 1-6                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-21                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-22                        [100, 4]                  --\n",
              "│    └─Linear: 2-23                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-24                     [100, 1]                  --\n",
              "├─Sequential: 1-7                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-25                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-26                        [100, 4]                  --\n",
              "│    └─Linear: 2-27                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-28                     [100, 1]                  --\n",
              "├─Sequential: 1-8                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-29                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-30                        [100, 4]                  --\n",
              "│    └─Linear: 2-31                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-32                     [100, 1]                  --\n",
              "├─Sequential: 1-9                        [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-33                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-34                        [100, 4]                  --\n",
              "│    └─Linear: 2-35                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-36                     [100, 1]                  --\n",
              "├─Sequential: 1-10                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-37                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-38                        [100, 4]                  --\n",
              "│    └─Linear: 2-39                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-40                     [100, 1]                  --\n",
              "├─Sequential: 1-11                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-41                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-42                        [100, 4]                  --\n",
              "│    └─Linear: 2-43                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-44                     [100, 1]                  --\n",
              "├─Sequential: 1-12                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-45                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-46                        [100, 4]                  --\n",
              "│    └─Linear: 2-47                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-48                     [100, 1]                  --\n",
              "├─Sequential: 1-13                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-49                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-50                        [100, 4]                  --\n",
              "│    └─Linear: 2-51                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-52                     [100, 1]                  --\n",
              "├─Sequential: 1-14                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-53                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-54                        [100, 4]                  --\n",
              "│    └─Linear: 2-55                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-56                     [100, 1]                  --\n",
              "├─Sequential: 1-15                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-57                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-58                        [100, 4]                  --\n",
              "│    └─Linear: 2-59                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-60                     [100, 1]                  --\n",
              "├─Sequential: 1-16                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-61                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-62                        [100, 4]                  --\n",
              "│    └─Linear: 2-63                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-64                     [100, 1]                  --\n",
              "├─Sequential: 1-17                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-65                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-66                        [100, 4]                  --\n",
              "│    └─Linear: 2-67                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-68                     [100, 1]                  --\n",
              "├─Sequential: 1-18                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-69                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-70                        [100, 4]                  --\n",
              "│    └─Linear: 2-71                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-72                     [100, 1]                  --\n",
              "├─Sequential: 1-19                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-73                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-74                        [100, 4]                  --\n",
              "│    └─Linear: 2-75                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-76                     [100, 1]                  --\n",
              "├─Sequential: 1-20                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-77                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-78                        [100, 4]                  --\n",
              "│    └─Linear: 2-79                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-80                     [100, 1]                  --\n",
              "├─Sequential: 1-21                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-81                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-82                        [100, 4]                  --\n",
              "│    └─Linear: 2-83                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-84                     [100, 1]                  --\n",
              "├─Sequential: 1-22                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-85                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-86                        [100, 4]                  --\n",
              "│    └─Linear: 2-87                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-88                     [100, 1]                  --\n",
              "├─Sequential: 1-23                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-89                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-90                        [100, 4]                  --\n",
              "│    └─Linear: 2-91                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-92                     [100, 1]                  --\n",
              "├─Sequential: 1-24                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-93                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-94                        [100, 4]                  --\n",
              "│    └─Linear: 2-95                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-96                     [100, 1]                  --\n",
              "├─Sequential: 1-25                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-97                      [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-98                        [100, 4]                  --\n",
              "│    └─Linear: 2-99                      [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-100                    [100, 1]                  --\n",
              "MyModel_using_optim                      [100, 1]                  49\n",
              "├─Sequential: 1-26                       [100, 1]                  (recursive)\n",
              "│    └─Linear: 2-101                     [100, 4]                  (recursive)\n",
              "│    └─ReLU: 2-102                       [100, 4]                  --\n",
              "│    └─Linear: 2-103                     [100, 1]                  (recursive)\n",
              "│    └─Sigmoid: 2-104                    [100, 1]                  --\n",
              "==========================================================================================\n",
              "Total params: 98\n",
              "Trainable params: 98\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.13\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.10\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.11\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}